{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "\n",
    "import fewshot_functions as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9695 files belonging to 97 classes.\n",
      "Using 7756 files for training.\n",
      "Found 9695 files belonging to 97 classes.\n",
      "Using 1939 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Define dataset parameters\n",
    "batch_size = 32\n",
    "img_size = (224, 224)  # Resize images to 224x224 (adjust to your model's input size)\n",
    "\n",
    "# Load dataset from 'data' folder with train-validation split\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data',                   # Root directory for your dataset\n",
    "    image_size=img_size,       # Resize images to 224x224 (or your model's input size)\n",
    "    batch_size=batch_size,     # Batch size for training\n",
    "    label_mode='int',          # Labels are returned as integer indices based on folder names\n",
    "    validation_split=0.2,      # Split 20% for validation\n",
    "    subset=\"training\",         # This is the training set\n",
    "    seed=123                   # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Normalize the pixel values to [0, 1] range (from 0-255)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Prefetch data for better performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV3Small documentation:\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "\n",
    "# Preloading with imagenet weights, excluding top layer as it the one we will be retraining\n",
    "base = MobileNetV3Small(input_shape=(224,224,3), \n",
    "                        weights=\"imagenet\", \n",
    "                        include_top=False,\n",
    "                        include_preprocessing=False\n",
    "                       )\n",
    "\n",
    "# Prevent imported weights from being retrained\n",
    "base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layers\n",
    "\n",
    "The embeddeding layer to be utilized by Fewshot will be set up here\n",
    "\n",
    "Prototypical Fewshot paper: https://arxiv.org/pdf/1703.05175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input tensor (224x224 image with 3 color channels; RGB)\n",
    "inputs = tf.keras.Input(shape=(224,224,3))\n",
    "\n",
    "# Pass inputs through base model\n",
    "x = base(inputs, training=False)\n",
    "\n",
    "# Convert feature maps to single feature vector per image; alternative, flatten(), is prone to overfitting\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Define number of classes in dataset; adjust as necessary\n",
    "outputs = Dense(128, activation='linear')(x)\n",
    "\n",
    "# Create customized model\n",
    "embedding_model = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reached a roadblock here, but this is what the fewshot training will look like. I do not want to proceed until we have the data imported and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:05:29.687904: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Loss = 3.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:05:31.015762: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-30 18:05:33.242176: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-30 18:05:37.731198: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-30 18:05:46.710123: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-30 18:06:04.586505: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50: Loss = 1.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:06:40.470119: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100: Loss = 1.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:07:52.572682: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 150: Loss = 1.6694\n",
      "Episode 200: Loss = 2.1463\n",
      "Episode 250: Loss = 1.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:10:16.331443: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300: Loss = 1.4995\n",
      "Episode 350: Loss = 0.5849\n",
      "Episode 400: Loss = 0.5105\n",
      "Episode 450: Loss = 0.6546\n",
      "Episode 500: Loss = 0.3345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:15:06.018492: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 550: Loss = 0.3323\n",
      "Episode 600: Loss = 0.5868\n",
      "Episode 650: Loss = 1.7164\n",
      "Episode 700: Loss = 0.7739\n",
      "Episode 750: Loss = 1.2735\n",
      "Episode 800: Loss = 0.3468\n",
      "Episode 850: Loss = 0.8548\n",
      "Episode 900: Loss = 0.9512\n",
      "Episode 950: Loss = 0.3840\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "episodes = 1000\n",
    "for episode in range(episodes):  # Train for 1000 episodes\n",
    "    support_images, support_labels, query_images, query_labels = fs.sample_episode(train_dataset)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Embed the support and query images\n",
    "        support_embeddings = embedding_model(support_images, training=True)\n",
    "        query_embeddings = embedding_model(query_images, training=True)\n",
    "        # Compute the loss\n",
    "        loss = fs.prototypical_loss(support_embeddings, support_labels, query_embeddings, query_labels)\n",
    "\n",
    "    # Update the model\n",
    "    gradients = tape.gradient(loss, embedding_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, embedding_model.trainable_variables))\n",
    "\n",
    "    # Log 1 episode in every 50\n",
    "    if episode % 50 == 0:\n",
    "        print(f\"Episode {episode}: Loss = {loss.numpy():.4f}\")\n",
    "\n",
    "    # Store for use later\n",
    "    embedding_model.save(\"mobilenetv3_fewshot.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
